{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjU3Rfhd3w5c"
   },
   "source": [
    "### **NOTE**:\n",
    "Due to limited Ed resources, the kernel may stop while training GRU/LSTMs.\n",
    "\n",
    "After completing this exercise, you can use the colab notebook below to train bigger networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDNueNGD3w5e"
   },
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/drive/1Wvwn44WaoPdrB8V2K2xQlqylnEP-U4WP?usp=sharing\" target=\"_blank\" >\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5e-Emzgk3w5f"
   },
   "source": [
    "## LSTM vs GRU\n",
    "\n",
    "We will use both GRU and LSTM to perform sentiment analysis in tensorflow.keras and compare their performance using the custom IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! pip install astroquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.gaia import Gaia\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dl_ind(datalink_dict, key, figsize = [15,5], fontsize = 12, linewidth = 2, show_legend = True, show_grid = True):\n",
    "    \"\"\n",
    "    \"Extract individual DataLink products and export them to an Astropy Table\"\n",
    "    \"\"\n",
    "    dl_out  = datalink_dict[key][0].to_table()\n",
    "    if 'time' in dl_out.keys():\n",
    "        plot_e_phot(dl_out, colours  = ['green', 'red', 'blue'], title = 'Epoch photometry', fontsize = fontsize, show_legend = show_legend, show_grid = show_grid, figsize = figsize)\n",
    "    if 'wavelength' in dl_out.keys():\n",
    "        if len(dl_out) == 343:  title = 'XP Sampled'\n",
    "        if len(dl_out) == 2401: title = 'RVS'\n",
    "        plot_sampled_spec(dl_out, color = 'blue', title = title, fontsize = fontsize, show_legend = False, show_grid = show_grid, linewidth = linewidth, legend = '', figsize = figsize)\n",
    "    return dl_out\n",
    "\n",
    "\n",
    "def plot_e_phot(inp_table, colours  = ['green', 'red', 'blue'], title = 'Epoch photometry', fontsize = 12, show_legend = True, show_grid = True, figsize = [15,5]):\n",
    "    \"\"\n",
    "    \"Epoch photometry plotter. 'inp_table' MUST be an Astropy-table object.\"\n",
    "    \"\"\n",
    "    fig      = plt.figure(figsize=figsize)\n",
    "    xlabel   = f'JD date [{inp_table[\"time\"].unit}]'\n",
    "    ylabel   = f'magnitude [{inp_table[\"mag\"].unit}]'\n",
    "    gbands   = ['G', 'RP', 'BP']\n",
    "    colours  = iter(colours)\n",
    "\n",
    "    plt.gca().invert_yaxis()\n",
    "    for band in gbands:\n",
    "        phot_set = inp_table[inp_table['band'] == band]\n",
    "        plt.plot(phot_set['time'], phot_set['mag'], 'o', label = band, color = next(colours))\n",
    "    make_canvas(title = title, xlabel = xlabel, ylabel = ylabel, fontsize= fontsize, show_legend=show_legend, show_grid = show_grid)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sampled_spec(inp_table, color = 'blue', title = '', fontsize = 14, show_legend = True, show_grid = True, linewidth = 2, legend = '', figsize = [12,4], show_plot = True):\n",
    "    \"\"\n",
    "    \"RVS & XP sampled spectrum plotter. 'inp_table' MUST be an Astropy-table object.\"\n",
    "    \"\"\n",
    "    if show_plot:\n",
    "        fig      = plt.figure(figsize=figsize)\n",
    "    xlabel   = f'Wavelength [{inp_table[\"wavelength\"].unit}]'\n",
    "    ylabel   = f'Flux [{inp_table[\"flux\"].unit}]'\n",
    "    plt.plot(inp_table['wavelength'], inp_table['flux'], '-', linewidth = linewidth, label = legend)\n",
    "    make_canvas(title = title, xlabel = xlabel, ylabel = ylabel, fontsize= fontsize, show_legend=show_legend, show_grid = show_grid)\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def make_canvas(title = '', xlabel = '', ylabel = '', show_grid = False, show_legend = False, fontsize = 12):\n",
    "    \"\"\n",
    "    \"Create generic canvas for plots\"\n",
    "    \"\"\n",
    "    plt.title(title,    fontsize = fontsize)\n",
    "    plt.xlabel(xlabel,  fontsize = fontsize)\n",
    "    plt.ylabel(ylabel , fontsize = fontsize)\n",
    "    plt.xticks(fontsize = fontsize)\n",
    "    plt.yticks(fontsize = fontsize)\n",
    "    if show_grid:\n",
    "        plt.grid()\n",
    "    if show_legend:\n",
    "        plt.legend(fontsize = fontsize*0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "Table size (rows): 2184477\n"
     ]
    }
   ],
   "source": [
    "#query = f\"SELECT * FROM gaiadr3.gaia_source WHERE has_epoch_photometry = 'TRUE' and source_id = 1035533795140608\"\n",
    "query = f\"SELECT source_id FROM gaiadr3.vari_eclipsing_binary\"\n",
    "\n",
    "job     = Gaia.launch_job_async(query)\n",
    "results = job.get_results()\n",
    "print(f'Table size (rows): {len(results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ids = len(results['source_id'].value.data)\n",
    "batch = 5000\n",
    "ids = results['source_id'].value.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000  downloaded\n",
      "10000  downloaded\n",
      "15000  downloaded\n",
      "20000  downloaded\n",
      "25000  downloaded\n",
      "30000  downloaded\n",
      "35000  downloaded\n",
      "40000  downloaded\n",
      "45000  downloaded\n",
      "50000  downloaded\n",
      "55000  downloaded\n",
      "60000  downloaded\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     batch_ids \u001b[38;5;241m=\u001b[39m ids[i\u001b[38;5;241m*\u001b[39mbatch:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch]\n\u001b[1;32m---> 11\u001b[0m datalink \u001b[38;5;241m=\u001b[39m \u001b[43mGaia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_release\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_release\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretrieval_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretrieval_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_structure\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_structure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m dl_keys  \u001b[38;5;241m=\u001b[39m [inp \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m datalink\u001b[38;5;241m.\u001b[39mkeys()]\n\u001b[0;32m     13\u001b[0m dl_keys\u001b[38;5;241m.\u001b[39msort()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\astroquery\\gaia\\core.py:283\u001b[0m, in \u001b[0;36mGaiaClass.load_data\u001b[1;34m(self, ids, data_release, data_structure, retrieval_type, valid_data, band, avoid_datatype_check, format, output_file, overwrite_output_file, verbose)\u001b[0m\n\u001b[0;32m    280\u001b[0m         log\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreation of the directory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m path)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__gaiadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     files \u001b[38;5;241m=\u001b[39m Gaia\u001b[38;5;241m.\u001b[39m__get_data_files(output_file\u001b[38;5;241m=\u001b[39moutput_file, path\u001b[38;5;241m=\u001b[39mpath)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\astroquery\\utils\\tap\\core.py:835\u001b[0m, in \u001b[0;36mTapPlus.load_data\u001b[1;34m(self, params_dict, output_file, verbose)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData request: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconnHandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_datapost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus, response\u001b[38;5;241m.\u001b[39mreason)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\astroquery\\utils\\tap\\conn\\tapconn.py:296\u001b[0m, in \u001b[0;36mTapConn.execute_datapost\u001b[1;34m(self, data, content_type, verbose)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m\"\"\"Executes a POST request\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03mThe connection is done through HTTP or HTTPS depending on the login\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03mstatus (logged in -> HTTPS)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;124;03mAn HTTP(s) response object\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    295\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_data_context()\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__execute_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\astroquery\\utils\\tap\\conn\\tapconn.py:427\u001b[0m, in \u001b[0;36mTapConn.__execute_post\u001b[1;34m(self, context, data, content_type, verbose)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__postHeaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m content_type\n\u001b[0;32m    426\u001b[0m conn\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, context, data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__postHeaders)\n\u001b[1;32m--> 427\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__currentReason \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mreason\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__currentStatus \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\http\\client.py:1371\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\http\\client.py:319\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 319\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\http\\client.py:280\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 280\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "retrieval_type = 'EPOCH_PHOTOMETRY'          # Options are: 'EPOCH_PHOTOMETRY', 'MCMC_GSPPHOT', 'MCMC_MSC', 'XP_SAMPLED', 'XP_CONTINUOUS', 'RVS', 'ALL'\n",
    "data_structure = 'INDIVIDUAL'   # Options are: 'INDIVIDUAL', 'COMBINED', 'RAW'\n",
    "data_release   = 'Gaia DR3'     # Options are: 'Gaia DR3' (default), 'Gaia DR2'\n",
    "\n",
    "k=0\n",
    "for i in range(264,math.ceil(total_ids/batch)):\n",
    "    if i * batch > total_ids:\n",
    "        batch_ids = ids[i*batch:total_ids]\n",
    "    else:\n",
    "        batch_ids = ids[i*batch:(i+1)*batch]\n",
    "    datalink = Gaia.load_data(ids=batch_ids, data_release = data_release, retrieval_type=retrieval_type, data_structure = data_structure, verbose = False, output_file = None)\n",
    "    dl_keys  = [inp for inp in datalink.keys()]\n",
    "    dl_keys.sort()\n",
    "    for dl_key in dl_keys:\n",
    "        datalink[dl_key][0].to_table().to_pandas().to_csv(\"./vari_eclipsing_binary/\"+dl_key+\".csv\")\n",
    "    k+=batch\n",
    "    print(k,\" downloaded\")\n",
    "\n",
    "print()\n",
    "print(f'The following Datalink products have been downloaded:')\n",
    "for dl_key in keys:\n",
    "    print(f' * {dl_key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ex1-scaffold.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
